{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "french-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considered-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "cell = 7\n",
    "bbox = 2\n",
    "class_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pointed-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBox():\n",
    "    def __init__(self, width, height, class_type, xmin, xmax, ymin, ymax):\n",
    "        xcenter = (xmin + xmax) / 2\n",
    "        ycenter = (ymin + ymax) / 2\n",
    "        self.center = xcenter / width, ycenter / height\n",
    "        self.size = (xmax - xmin) / width, (ymax - ymin) / height\n",
    "        self.class_type = class_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assigned-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def resize_image(image, size):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "def norm_image(image):\n",
    "    image = image / 255\n",
    "    return image.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlikely-space",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007_000027.jpg\n",
      "2008_000492.jpg\n",
      "2008_002508.jpg\n"
     ]
    }
   ],
   "source": [
    "def read_training_data(label_folder, image_folder, n=-1):\n",
    "    if label_folder.endswith('/'):\n",
    "        label_folder = label_foder[:-1]\n",
    "    if image_folder.endswith('/'):\n",
    "        image_folder = image_foder[:-1]\n",
    "    label_files = glob.glob(label_folder + '/*.xml')\n",
    "    raw_data = []\n",
    "    for i, file in enumerate(label_files):\n",
    "        if i == n:\n",
    "            break\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "        image_filename = root.find('filename').text\n",
    "        if i % 1000 == 0:\n",
    "            print(image_filename)\n",
    "        image = read_image(image_folder + '/' + image_filename)\n",
    "        image = resize_image(image, (448, 448))\n",
    "        image = norm_image(image)\n",
    "        image_width = float(root.find('size').find('width').text)\n",
    "        image_height = float(root.find('size').find('height').text)\n",
    "        object_size = len(root.findall('object'))\n",
    "        boxes = []\n",
    "        for obj in root.findall('object'):\n",
    "            name = obj.find('name').text\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = float(bndbox.find('xmin').text); ymin = float(bndbox.find('ymin').text)\n",
    "            xmax = float(bndbox.find('xmax').text); ymax = float(bndbox.find('ymax').text)\n",
    "            class_type = class_names.index(name)\n",
    "            boxes.append(BoundingBox(image_width, image_height, class_type, xmin, xmax, ymin, ymax))\n",
    "        raw_data.append((image, file, boxes))\n",
    "    return raw_data\n",
    "\n",
    "raw_data = read_training_data('./VOCdevkit/VOC2012/Annotations', './VOCdevkit/VOC2012/JPEGImages', 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strange-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[:, cell, cell, B * 5 + C]\n",
    "def create_data_label(raw_data):\n",
    "    data = []\n",
    "    labels = np.empty((0, cell, cell, (bbox * 5 + class_num)))\n",
    "    for rd in raw_data:\n",
    "        data.append(rd[0])\n",
    "        class_probs = np.zeros((cell, cell, class_num))\n",
    "        object_probs = np.zeros((cell, cell, bbox))\n",
    "        cx = np.zeros((cell, cell, bbox))\n",
    "        cy = np.zeros((cell, cell, bbox))\n",
    "        sqrt_w = np.zeros((cell, cell, bbox))\n",
    "        sqrt_h = np.zeros((cell, cell, bbox))\n",
    "        \n",
    "        for box in rd[2]:\n",
    "            icx, icy = (np.floor(np.asarray(box.center) * cell)).astype(np.int)\n",
    "            b = 1 if object_probs[icy][icx][0] == 1 else 0\n",
    "            object_probs[icy][icx][b] = 1\n",
    "            cx_normed = box.center[0] * cell - icx\n",
    "            cy_normed = box.center[1] * cell - icy\n",
    "            cx[icy][icx][b] = cx_normed\n",
    "            cy[icy][icx][b] = cy_normed\n",
    "            sqrt_w[icy][icx][b] = np.sqrt(box.size[0])\n",
    "            sqrt_h[icy][icx][b] = np.sqrt(box.size[1])\n",
    "            class_probs[icy][icx][box.class_type] = 1\n",
    "        \n",
    "        for y in range(cell):\n",
    "            for x in range(cell):\n",
    "                cnt = 0\n",
    "                for i in range(class_num):\n",
    "                    if class_probs[y][x][i] == 1:\n",
    "                        cnt += 1\n",
    "                if cnt == 0:\n",
    "                    continue\n",
    "                for i in range(class_num):\n",
    "                    if class_probs[y][x][i] == 1:\n",
    "                        class_probs[y][x][i] = 1 / cnt\n",
    "        \n",
    "        label = np.empty((cell, cell, (bbox * 5 + class_num)))\n",
    "        label[:, :, 0:5*bbox:5] = object_probs[:, :, :]\n",
    "        label[:, :, 1:5*bbox:5] = cx[:, :, :]\n",
    "        label[:, :, 2:5*bbox:5] = cy[:, :, :]\n",
    "        label[:, :, 3:5*bbox:5] = sqrt_w[:, :, :]\n",
    "        label[:, :, 4:5*bbox:5] = sqrt_h[:, :, :]\n",
    "        label[:, :, 5*bbox:] = class_probs[:, :, :]\n",
    "        \n",
    "        labels = np.append(labels, [label], axis=0)\n",
    "    data = np.asarray(data)\n",
    "    return data, labels\n",
    "\n",
    "data, labels = create_data_label(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "split-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[batch, cell, cell, B * 5 + C]\n",
    "def customloss(outputs, targets):\n",
    "    #[batch, cell, cell, C]\n",
    "    output_class_probs = outputs[:, :, :, 5*bbox:]\n",
    "    target_class_probs = targets[:, :, :, 5*bbox:]\n",
    "    \n",
    "    #[batch, cell, cell, B]\n",
    "    output_xc_normed = outputs[:, :, :, 1:5*bbox:5]\n",
    "    output_yc_normed = outputs[:, :, :, 2:5*bbox:5]\n",
    "    output_sqrt_w = outputs[:, :, :, 3:5*bbox:5]\n",
    "    output_sqrt_h = outputs[:, :, :, 4:5*bbox:5]\n",
    "    output_w = outputs[:, :, :, 3:5*bbox:5] ** 2\n",
    "    output_h = outputs[:, :, :, 4:5*bbox:5] ** 2\n",
    "    target_xc_normed = targets[:, :, :, 1:5*bbox:5]\n",
    "    target_yc_normed = targets[:, :, :, 2:5*bbox:5]\n",
    "    target_sqrt_w = targets[:, :, :, 3:5*bbox:5]\n",
    "    target_sqrt_h = targets[:, :, :, 4:5*bbox:5]\n",
    "    target_w = targets[:, :, :, 3:5*bbox:5] ** 2\n",
    "    target_h = targets[:, :, :, 4:5*bbox:5] ** 2\n",
    "    output_xc = torch.empty_like(output_xc_normed)\n",
    "    output_yc = torch.empty_like(output_xc_normed)\n",
    "    target_xc = torch.empty_like(output_xc_normed)\n",
    "    target_yc = torch.empty_like(output_xc_normed)\n",
    "    for i in range(cell):\n",
    "        output_xc[:, :, i, :] = i / cell + output_xc_normed[:, :, i, :] / cell\n",
    "        output_yc[:, i, :, :] = i / cell + output_yc_normed[:, i, :, :] / cell\n",
    "        target_xc[:, :, i, :] = i / cell + target_xc_normed[:, :, i, :] / cell\n",
    "        target_yc[:, i, :, :] = i / cell + target_yc_normed[:, i, :, :] / cell\n",
    "    dx = torch.minimum(output_xc + output_w / 2, target_xc + target_w / 2) - torch.maximum(output_xc - output_w / 2, target_xc - target_w / 2)\n",
    "    dy = torch.minimum(output_yc + output_h / 2, target_yc + target_h / 2) - torch.maximum(output_yc - output_h / 2, target_yc - target_h / 2)\n",
    "    IoU = torch.maximum(torch.zeros_like(output_xc), dx * dy / output_w * output_h + target_w * target_h - dx * dy)\n",
    "    output_confs = IoU * outputs[:, :, :, 0:5*bbox:5]\n",
    "    \n",
    "    indicator_obj_perbbox = targets[:, :, :, 0:5*bbox:5]\n",
    "    indicator_obj_percell = targets[:, :, :, 0]\n",
    "    lambda_coord = 5\n",
    "    lambda_noobj = 0.5\n",
    "    loss = torch.sum((lambda_coord * indicator_obj_perbbox \n",
    "        * ((output_xc - target_xc) ** 2 + (output_yc - target_yc) ** 2\n",
    "         + (output_sqrt_w - target_sqrt_w) ** 2 + (output_sqrt_h - target_sqrt_h)**2)\n",
    "        + indicator_obj_perbbox * (output_confs - 1) ** 2 \n",
    "        + lambda_noobj * indicator_obj_perbbox * (output_confs - 1) ** 2), dim=(1, 2, 3)) \\\n",
    "        + torch.sum(indicator_obj_percell * torch.sum((output_class_probs - target_class_probs) ** 2, dim=-1), dim=(1, 2))\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "active-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 192, 3)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(192, 128, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, 1)\n",
    "        self.conv6 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv10 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv12 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv14 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv15 = nn.Conv2d(512, 512, 1)\n",
    "        self.conv16 = nn.Conv2d(512, 1024, 3, padding=1)\n",
    "        \n",
    "        self.conv17 = nn.Conv2d(1024, 512, 1)\n",
    "        self.conv18 = nn.Conv2d(512, 1024, 3, padding=1)\n",
    "        self.conv19 = nn.Conv2d(1024, 512, 1)\n",
    "        self.conv20 = nn.Conv2d(512, 1024, 3, padding=1)\n",
    "        self.conv21 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.conv22 = nn.Conv2d(1024, 1024, 3, stride=2, padding=1)\n",
    "        \n",
    "        self.conv23 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.conv24 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 1024, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 7 * 7 * 30)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.1)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv2(x), 0.1)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv3(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv4(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv5(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv6(x), 0.1)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv7(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv8(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv9(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv10(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv11(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv12(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv13(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv14(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv15(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv16(x), 0.1)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv17(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv18(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv19(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv20(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv21(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv22(x), 0.1)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv23(x), 0.1)\n",
    "        x = F.leaky_relu(self.conv24(x), 0.1)\n",
    "        \n",
    "        x = x.reshape(-1,  7 * 7 * 1024)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x.view(-1, 7, 7, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "structural-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = torch.from_numpy(data[0]).type(torch.float)\n",
    "        self.label = torch.from_numpy(data[1]).type(torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.label[idx]\n",
    "        if self.transform:\n",
    "            out_data = self.transform(out_data)\n",
    "        return out_data, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wired-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset((data, labels), transform=None)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forward-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 7, 7, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = iter(trainloader)\n",
    "train_iter.next()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "taken-athens",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 37748736 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8440d6bbe5e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Waseda_DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2c104464412c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv20\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv21\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv22\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv23\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Waseda_DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Waseda_DataScience\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Waseda_DataScience\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 420\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 37748736 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = customloss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        print(running_loss)\n",
    "#         if i % 2500 == 2499:\n",
    "#             print(f'epoch: {epoch} batch: {i} loss: {running_loss/2500}')\n",
    "#             running_loss = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
